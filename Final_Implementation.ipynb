{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOl3lzN+oF3r91UcUVPorV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dongrekunal/Autonomous-Vehicle-Perception/blob/main/Final_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Autonomous Car Project\n",
        "\n",
        "\n",
        "<img src=\"https://www.cdc.gov/sleep/images/featured-topics/DrowsyDriving_Dashboard.jpg?_=47870\" width=\"900\" height=\"500\">\n",
        "\n"
      ],
      "metadata": {
        "id": "gJjfIQoFUbLG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MvZG3jPbDsU",
        "outputId": "08edb103-5227-4d7b-990e-36b11540de9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Autonomous-Vehicle-Perception'...\n",
            "remote: Enumerating objects: 103, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 103 (delta 1), reused 0 (delta 0), pack-reused 97\u001b[K\n",
            "Receiving objects: 100% (103/103), 1.50 MiB | 4.31 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dongrekunal/Autonomous-Vehicle-Perception.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Autonomous-Vehicle-Perception/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ena-RXdIbLgm",
        "outputId": "d350f474-48bf-4cbb-f637-a71d1148447b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Autonomous-Vehicle-Perception\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnoxTpXVbtLS",
        "outputId": "7a96198c-cbb5-4435-8952-713ddc3a28ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes.txt  imgs\t\t LICENSE  PINet      requirements.txt  yolov5\n",
            "elements     Instructions.ipynb  main.py  README.md  SGDepth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijkHwr2Lb-_N",
        "outputId": "f19b69c1-f3ca-41b4-f9df-9b10f488660e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (0.29.34)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.10.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (0.15.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (4.65.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (0.12.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 14)) (1.4.4)\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.39.3)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (3.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (3.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.9.1->-r requirements.txt (line 10)) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.9.1->-r requirements.txt (line 10)) (3.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.10.1->-r requirements.txt (line 11)) (2.27.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->-r requirements.txt (line 14)) (2022.7.1)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.9.1->-r requirements.txt (line 10)) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.10.1->-r requirements.txt (line 11)) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.10.1->-r requirements.txt (line 11)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.10.1->-r requirements.txt (line 11)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.10.1->-r requirements.txt (line 11)) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.9.1->-r requirements.txt (line 10)) (1.3.0)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.13.4 timm-0.6.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading weights and videos from our Google drive and copying it to current dir. Then unzip them"
      ],
      "metadata": {
        "id": "s0MUFM0YcHEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls  #No videos.zip & weights.zip present but after copying the show in our list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfKaxm1Pd3n_",
        "outputId": "ec449847-931f-412f-9a7b-3f7e90dba36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes.txt  imgs\t\t LICENSE  PINet      requirements.txt  yolov5\n",
            "elements     Instructions.ipynb  main.py  README.md  SGDepth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp  '/content/gdrive/My Drive/videos.zip' 'videos.zip'\n",
        "!cp -b '/content/gdrive/MyDrive/weights.zip' 'weights.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPev_BaVeLVE",
        "outputId": "68042adb-83c4-4bbf-bfbb-26b1eaf7100e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o-NYelIljjSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls #This is after copying them now videos.zip & weights.zip are visible"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LILJu47mfk7E",
        "outputId": "63f4376f-474f-417d-a6ac-a123d6721077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes.txt  Instructions.ipynb  PINet\t\t   SGDepth\tyolov5\n",
            "elements     LICENSE\t\t README.md\t   videos.zip\n",
            "imgs\t     main.py\t\t requirements.txt  weights.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./videos.zip\n",
        "!unzip ./weights.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iqeW7HHgTtM",
        "outputId": "3ed22e8a-a055-4a2f-decc-3119399a9690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./videos.zip\n",
            "   creating: videos/\n",
            "  inflating: videos/test1.mp4        \n",
            "  inflating: videos/test10.mp4       \n",
            "  inflating: videos/test11.mp4       \n",
            "  inflating: videos/test2.mp4        \n",
            "  inflating: videos/test3.mp4        \n",
            "  inflating: videos/test4.mp4        \n",
            "  inflating: videos/test5.mp4        \n",
            "  inflating: videos/test6.mp4        \n",
            "  inflating: videos/test7.mp4        \n",
            "  inflating: videos/test8.mp4        \n",
            "  inflating: videos/test9.mp4        \n",
            "Archive:  ./weights.zip\n",
            "   creating: weights/\n",
            "  inflating: weights/best_sign.pt    \n",
            "  inflating: weights/culane_model.pkl  \n",
            "  inflating: weights/light_RegNety002.pth  \n",
            "  inflating: weights/sgdepth_model.pth  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) **Local:** video test[1-7].mp4\n",
        "- **day:** videos test[1-5].mp4\n",
        "- **night:** videos test[6, 7].mp4\n",
        "\n",
        "2) **BDD100K:**\n",
        "- **day:** videos test[8-10-11].mp4\n",
        "- **night:** videos test[9].mp4"
      ],
      "metadata": {
        "id": "o2bvlbXWg0PC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test video\n"
      ],
      "metadata": {
        "id": "nNI5en-ck8mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "HTML('<iframe width=\"760\" height=\"415\" src=\"https://www.youtube.com/embed/HRck-piUUwY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')\n",
        "\n",
        "# Pune video\n",
        "# NYC video\n",
        "# London video\n",
        "\n",
        "# Dubai video\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "CK8MRlEtmFjI",
        "outputId": "417545d0-41c3-42dc-e2cb-852124fd1844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"760\" height=\"415\" src=\"https://www.youtube.com/embed/HRck-piUUwY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube\n",
        "link = 'https://youtu.be/HRck-piUUwY'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxpZymYKNJB2",
        "outputId": "e11d90dd-cc19-4004-ee35-67d6b0573ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os, sys\n",
        "from pytube import YouTube\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/Autonomous-Vehicle-Perception/videos\")\n",
        "\n",
        "youtube = YouTube(link)\n",
        "\n",
        "print(youtube.title)\n",
        "video = youtube.streams.get_highest_resolution()\n",
        "video.download()\n",
        "\n",
        "old_name = r\"/content/Autonomous-Vehicle-Perception/videos/Mumbai City.mp4\"\n",
        "new_name = r\"/content/Autonomous-Vehicle-Perception/videos/Mumbai_City.mp4\"\n",
        "os.rename(old_name, new_name)\n",
        "!pwd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfkbH83TO34j",
        "outputId": "290ea3f7-f3a6-46bf-dbc7-42817f8e86e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mumbai City\n",
            "/content/Autonomous-Vehicle-Perception/videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run \n",
        "- **--video**       [The input video] \n",
        "- **--noshow**      [Do not Show the output frames]\n",
        "- **--save**        [Saving the output video]\n",
        "- **--output-name** [Outputput video name]\n",
        "- **--mode** ['night', if you want to test the night test videos. default: 'day']\n",
        "\n",
        "\n",
        "- Ouptput will show how much layer with parameter present for video.\n",
        "- `[Input Video : Name ] `\n",
        "- `[16/949 Frames Processed]`  From total frames how many currently scanned\n",
        "- `[FPS : 0.133714] [ET : 1:56:02]` FPS passing rate ET will be showing estimated time HRS \n"
      ],
      "metadata": {
        "id": "PgcDsLsdh_RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUURSEFvRU6X",
        "outputId": "5d34fddb-7139-40de-c2ec-086e4cff4492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Autonomous-Vehicle-Perception\n",
            "/content/Autonomous-Vehicle-Perception\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --video ./videos/Mumbai_City.mp4 --noshow --save --output-name 'MumbaiCity'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoKlPoGbg2RN",
        "outputId": "a5cc8d5d-69e7-4452-e58f-71bbd86c6278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Yolov5 model loaded!\n",
            "YOLOv5 üöÄ 2023-4-11 Python-3.9.16 torch-2.0.0+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "newYOLOv5s summary: 213 layers, 7047883 parameters, 0 gradients\n",
            "Adding AutoShape... \n",
            "Sign model loaded!\n",
            "Traffic light classifier loaded!\n",
            "CULane model loaded!\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 72.6MB/s]\n",
            "SGDepth model loaded!\n",
            "outputs/MumbaiCity\n",
            "[Input Video : ./videos/Mumbai_City.mp4] [138/1893 Frames Processed] [FPS : 0.148692] [ET : 3:16:18]Traceback (most recent call last):\n",
            "  File \"/content/Autonomous-Vehicle-Perception/main.py\", line 91, in <module>\n",
            "    frame = lane_detector.detect_lane(frame, masked_image)\n",
            "  File \"/content/Autonomous-Vehicle-Perception/elements/PINet.py\", line 40, in detect_lane\n",
            "    _, _, ti = self.test(np.array([frame]), org_frame, mask, self.threshold_point) \n",
            "  File \"/content/Autonomous-Vehicle-Perception/elements/PINet.py\", line 56, in test\n",
            "    result = self.predict_lanes_test(test_images)\n",
            "  File \"/content/Autonomous-Vehicle-Perception/elements/PINet.py\", line 49, in predict_lanes_test\n",
            "    outputs, _ = self.lane_agent(inputs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/Autonomous-Vehicle-Perception/PINet/hourglass_network.py\", line 28, in forward\n",
            "    result4, out, feature4 = self.layer4(out)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/Autonomous-Vehicle-Perception/PINet/util_hourglass.py\", line 297, in forward\n",
            "    out_offset = self.out_offset(outputs_a)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/Autonomous-Vehicle-Perception/PINet/util_hourglass.py\", line 169, in forward\n",
            "    outputs = self.conv1(inputs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/Autonomous-Vehicle-Perception/PINet/util_hourglass.py\", line 26, in forward\n",
            "    outputs = self.cbr_unit(inputs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\", line 217, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XJd3SRWhtFop"
      }
    }
  ]
}